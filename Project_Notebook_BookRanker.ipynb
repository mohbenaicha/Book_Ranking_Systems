{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ae282d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moham\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c2d22",
   "metadata": {},
   "source": [
    "Importing and organizing the raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0260233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# data = list()\n",
    "# for file in os.listdir(\"./data\"):\n",
    "##     if file != \"results_20000-24861.json\":\n",
    "#     with open(\"./data/\"+file, 'rb') as f:\n",
    "#         print(f\"Read {file}\")\n",
    "#         data_ = json.load(f)\n",
    "#         data += data_\n",
    "##     else:\n",
    "##         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee7f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# records = [{\"User\": record.get('user_id'), \n",
    "#            \"ISBN\": record.get('book_title'),\n",
    "#            \"RatingOf5\": record.get('stars'),\n",
    "#            \"Genres\": record.get('genres')\n",
    "#           } for record in data]\n",
    "# df = pd.DataFrame(records)\n",
    "# df.to_csv(\"USER_ISBN_RATING_GENRES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "9e423556",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../USER_ISBN_RATING_GENRES.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "2bce96ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numer of unique books:  57198\n",
      "Total numer of unique users:  706880\n",
      "Total numer of reviews:  1733561\n",
      "Total numer of positive reviews:  936796\n",
      "Total numer of non-positive reviews:  201628\n",
      "Total numer of moderate reviews:  372374\n",
      "Total numer of  non-reviews:  222763\n"
     ]
    }
   ],
   "source": [
    "print(\"Total numer of unique books: \", len(df[\"ISBN\"].unique()))\n",
    "print(\"Total numer of unique users: \", len(df[\"User\"].unique()))\n",
    "print(\"Total numer of reviews: \", len(df))\n",
    "print(\"Total numer of positive reviews: \", len(df[df[\"RatingOf5\"] > 3]))\n",
    "print(\"Total numer of non-positive reviews: \", len(df[df[\"RatingOf5\"] < 3]))\n",
    "print(\"Total numer of moderate reviews: \", len(df[df[\"RatingOf5\"] == 3]))\n",
    "print(\"Total numer of  non-reviews: \", sum(df[\"RatingOf5\"].isna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45c216",
   "metadata": {},
   "source": [
    "Although I'll use a TF stringlookup object to encode users, to keep users anonymous for the data exploration stage, I'll label encode them as IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "129056e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1733561, 706880)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df[\"User\"])\n",
    "transformed = le.transform(df[\"User\"])\n",
    "len(transformed), len(np.unique(transformed, return_counts=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "efc5427f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ranker_fitted_label_encoder.pkl']"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(le, \"ranker_fitted_label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "9c9afe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = joblib.load(\"ranker_fitted_label_encoder.pkl\")\n",
    "transformed = le.transform(df[\"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "6649eba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    423114\n",
       "1    241063\n",
       "2    659623\n",
       "3    557019\n",
       "4     44930\n",
       "Name: User, dtype: int32"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"User\"] = transformed\n",
    "df[\"User\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "848a364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1817c",
   "metadata": {},
   "source": [
    "**I'm going to reserve a random sample of 10 observations to test recommendations as observations that the model has not seen before when developing the production package.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "1b1be76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "b5ea0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.groupby(\"ISBN\").count()[df.groupby(\"ISBN\").count()[\"User\"] > 5][\"User\"]. \\\n",
    "    sort_values(ascending=False).sample(20).index\n",
    "loop = True\n",
    "while True:\n",
    "    new_sample=df[df[\"ISBN\"].isin(sample)].sample(10)['ISBN']\n",
    "    if len(new_sample.unique()) == 10:\n",
    "        sample_to_keep = new_sample\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "03f41a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df[df.index.isin(sample_to_keep.index)][['User', 'ISBN', 'RatingOf5']]\n",
    "index_to_drop = sample.index\n",
    "sample.to_csv('ranker_test.csv', index=False)\n",
    "df.drop(index=index_to_drop, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "24e9dd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>RatingOf5</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [User, ISBN, RatingOf5, Genres]\n",
       "Index: []"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index.isin(index_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "bb651465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320727</td>\n",
       "      <td>What Went Wrong at Enron: Everyone's Guide to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625088</td>\n",
       "      <td>Guerrilla Learning: How to Give Your Kids a Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>618800</td>\n",
       "      <td>Eastern Sun Winter Moon: An Autobiographical O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>411288</td>\n",
       "      <td>Raspberry Crush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198921</td>\n",
       "      <td>Pooh: Just Be Nice AND NOT TOO ROUGH SPECIAL E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>258203</td>\n",
       "      <td>The Life and Adventures of Nicholas Nickleby V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>336651</td>\n",
       "      <td>Silver Flame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>684707</td>\n",
       "      <td>Nothing That Meets the Eye: The Uncollected St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>597291</td>\n",
       "      <td>Das Tor ins Nichts Der Magier 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>404510</td>\n",
       "      <td>Berserk: Motiveless Random Massacres</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User                                               ISBN\n",
       "0  320727  What Went Wrong at Enron: Everyone's Guide to ...\n",
       "1  625088  Guerrilla Learning: How to Give Your Kids a Re...\n",
       "2  618800  Eastern Sun Winter Moon: An Autobiographical O...\n",
       "3  411288                                    Raspberry Crush\n",
       "4  198921  Pooh: Just Be Nice AND NOT TOO ROUGH SPECIAL E...\n",
       "5  258203  The Life and Adventures of Nicholas Nickleby V...\n",
       "6  336651                                       Silver Flame\n",
       "7  684707  Nothing That Meets the Eye: The Uncollected St...\n",
       "8  597291                    Das Tor ins Nichts Der Magier 2\n",
       "9  404510               Berserk: Motiveless Random Massacres"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('ranker_test.csv')[['User', 'ISBN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d1a738f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"User\", \"ISBN\", \"RatingOf5\", \"Genres\"]].to_csv('ranker_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a990170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423114</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241063</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>659623</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>557019</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44930</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User                    ISBN\n",
       "0  423114  Kiss Hollywood Goodbye\n",
       "1  241063  Kiss Hollywood Goodbye\n",
       "2  659623  Kiss Hollywood Goodbye\n",
       "3  557019  Kiss Hollywood Goodbye\n",
       "4   44930  Kiss Hollywood Goodbye"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('ranker_train_data.csv', nrows=5)[[\"User\", \"ISBN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "c000ec0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User         0\n",
       "ISBN         0\n",
       "RatingOf5    0\n",
       "Genres       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc6642",
   "metadata": {},
   "source": [
    "#### Reducing dimentionality\n",
    "\n",
    "With ~ 700k users and 60k books, the embeddings for the two embedding \"towers\" that the recommender model is going to be based on will generately an extremely large model. Practically, I would like to demonstrate the end-to-end data science pipeline by being able to package my model and make it available publicly for my API to access as well as for those interested which is why reduce the recommendations to those users who given more than 2 review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "af78f7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User\n",
       "0         41\n",
       "7          3\n",
       "8          4\n",
       "25         3\n",
       "31         3\n",
       "          ..\n",
       "706863    12\n",
       "706867     6\n",
       "706870     6\n",
       "706871     4\n",
       "706879     4\n",
       "Name: ISBN, Length: 115057, dtype: int64"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data = df.groupby(\"User\").count()\n",
    "grouped_data[grouped_data[\"ISBN\"] > 2]['ISBN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "dbffddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_keep = grouped_data[grouped_data[\"ISBN\"] > 2].index\n",
    "set(idx_to_keep) == set(df[df[\"User\"].isin(idx_to_keep)][\"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "e217c46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234345</th>\n",
       "      <td>244283</td>\n",
       "      <td>Lovers Crossing Roscoe Brinker 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129545</th>\n",
       "      <td>418961</td>\n",
       "      <td>Great Russian Short Stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267580</th>\n",
       "      <td>360211</td>\n",
       "      <td>Calendar: Humanity's Epic Struggle To Determin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348615</th>\n",
       "      <td>39372</td>\n",
       "      <td>Moss Rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601934</th>\n",
       "      <td>91590</td>\n",
       "      <td>The Lonely Ships: The Life and Death of the US...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           User                                               ISBN\n",
       "234345   244283                   Lovers Crossing Roscoe Brinker 1\n",
       "129545   418961                        Great Russian Short Stories\n",
       "1267580  360211  Calendar: Humanity's Epic Struggle To Determin...\n",
       "348615    39372                                          Moss Rose\n",
       "601934    91590  The Lonely Ships: The Life and Death of the US..."
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.User.isin(idx_to_keep)]\n",
    "df.sample(5)[['User', 'ISBN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb70607",
   "metadata": {},
   "source": [
    "At this point we have an index of user that have more than 2 reviews (of different books). Our new DataFrame object will only comprise those users and their respectively reviewed books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "3a90e802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique users remaining:  115057\n",
      "# of unique books remaining:  54466\n"
     ]
    }
   ],
   "source": [
    "# also ensure that the grouping and querying was sane\n",
    "print(\"# of unique users remaining: \", len(df.groupby('User').count()))\n",
    "\n",
    "# also check out how many unique books were lost in the process of trimming \n",
    "# down the dataset (only about 500)\n",
    "\n",
    "print(\"# of unique books remaining: \", len(df.groupby('ISBN').count()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "99e941df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can label encode the book ID's if required, otherwise, a TF stringlookup object can handle \n",
    "# a variety of string encodings well - as will follow\n",
    "\n",
    "le_isbn = LabelEncoder()\n",
    "df[\"ISBN\"] = le_isbn.fit_transform(df[\"ISBN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "ca302f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 924369 entries, 0 to 1733560\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   User       924369 non-null  int64 \n",
      " 1   ISBN       924369 non-null  int64 \n",
      " 2   RatingOf5  924369 non-null  int64 \n",
      " 3   Genres     924369 non-null  object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.User = df.User.astype(np.int64)\n",
    "df.ISBN = df.ISBN.astype(np.int64)\n",
    "df.RatingOf5 = df.RatingOf5.astype(np.int64)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348882f3",
   "metadata": {},
   "source": [
    "Setting up tensors to batch for purposes of training the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "a3689c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = tf.data.Dataset.from_tensor_slices(df['ISBN'].astype('str').values)\n",
    "ratings = tf.data.Dataset.from_tensor_slices(df[['User', 'ISBN', 'RatingOf5']].astype('str').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "e95a97db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df)*0.8)\n",
    "train = tf.data.Dataset.from_tensor_slices(\n",
    "    df[[\"ISBN\", \"User\", \"RatingOf5\"]][:train_size].astype('str').values).shuffle(100000)\n",
    "test = tf.data.Dataset.from_tensor_slices(\n",
    "    df[[\"ISBN\", \"User\", \"RatingOf5\"]][train_size:].astype('str').values).shuffle(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "07607de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'33888' b'75806' b'3'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in test.take(1):\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae1f6b",
   "metadata": {},
   "source": [
    "String look up creates a vocabulary dictionary of string-value pairs since I'll be embedding my ISBN's and users ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c94c80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(ratings.map(lambda x: x[0]))\n",
    "\n",
    "book_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "book_titles_vocabulary.adapt(ratings.map(lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "411626e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ranker_user_ids_vocabulary\", user_ids_vocabulary.get_weights())\n",
    "np.save(\"ranker_book_titles_vocabulary\", book_titles_vocabulary.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "d0f74510",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id_stringlookup = tf.keras.layers.StringLookup(mask_token=None)\n",
    "new_user_id_stringlookup.set_weights(np.load(\"ranker_user_ids_vocabulary.npy\", allow_pickle=True))\n",
    "\n",
    "new_book_title_stringlookup = tf.keras.layers.StringLookup(mask_token=None)\n",
    "new_book_title_stringlookup.set_weights(np.load(\"ranker_book_titles_vocabulary.npy\", allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "8896f024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique User ID counts:  115057 115059\n",
      "Unique ISBN counts:  54466 54467\n"
     ]
    }
   ],
   "source": [
    "# compare vocab against original data as a sanity check\n",
    "print(\"Unique User ID counts: \", len(df[\"User\"].unique()), new_user_id_stringlookup.vocabulary_size())\n",
    "print(\"Unique ISBN counts: \", len(df[\"ISBN\"].unique()), new_book_title_stringlookup.vocabulary_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100ec6d",
   "metadata": {},
   "source": [
    "The difference in \"vocab\" counts results from the [UNK] (i.e. unknown) token. There is also a duplicate User in the string lookup for some reason that can be removed if required, otherwise, it shouldn't affect the lookup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0c9cc",
   "metadata": {},
   "source": [
    "Several user_ids have a string lookup of 0 which stands for unknown meaning they were likely dropped during the attemp at dimentionality reduction (i.e. these users had only ever reviewed one/two books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "63866a0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [518]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# # this is a bit of  confusing one-liner that simply attempts to search for the indices of users that \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# # had the string lookup assign them a value of 0 and thus are the suspicions confirmed that\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# # they've been dropped during the dimentionality reduction step since they're users with less than \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# # 2 total reviews.\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df[df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(sample[sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(idx)]\u001b[38;5;241m.\u001b[39mindex)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "idx = [0, 3, 8]\n",
    "\n",
    "# # this is a bit of  confusing one-liner that simply attempts to search for the indices of users that \n",
    "# # had the string lookup assign them a value of 0 and thus are the suspicions confirmed that\n",
    "# # they've been dropped during the dimentionality reduction step since they're users with less than \n",
    "# # 2 total reviews.\n",
    "\n",
    "assert len(df[df.index.isin(sample[sample['User'].reset_index().index.isin(idx)].index)]['User'].unique()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1873a44d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "I'll be doing tests for label encoders and string lookups on the books columns and not the users columns before deployment \n",
    "since their info is confidential, otherwise, for testing purposes, the sample taken isn't valid and would fail the tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9e09f",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d073e7d7",
   "metadata": {},
   "source": [
    "The following class enherits from the TF Model class and sets up the embedding layers for users and books that will fed into a DNN with a resultant rank. The goal is to reduce the MSE between this rank and actual user rating for a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "216e19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, book_title_stringlookup, user_id_stringlookup):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([user_id_stringlookup,\n",
    "          tf.keras.layers.Embedding(user_id_stringlookup.vocabulary_size()+1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for books.\n",
    "        self.book_embeddings = tf.keras.Sequential([book_title_stringlookup,\n",
    "          tf.keras.layers.Embedding(book_title_stringlookup.vocabulary_size()+1, embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, book_title = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        book_embedding = self.book_embeddings(book_title)\n",
    "\n",
    "        return self.ratings(tf.concat([user_embedding, book_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "7d4d98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRecommenderModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel(new_book_title_stringlookup, new_user_id_stringlookup)\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "          loss = tf.keras.losses.MeanSquaredError(),\n",
    "          metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features: dict) -> tf.Tensor:\n",
    "        return self.ranking_model(\n",
    "            (features[:, 1], features[:, 0]))\n",
    "\n",
    "    def compute_loss(self, features: dict, training=False) -> tf.Tensor:\n",
    "\n",
    "        labels =  tf.strings.to_number(features[:,2])\n",
    "\n",
    "        rating_predictions = self(features[:, :2])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "c634ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BookRecommenderModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "522ab772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book b'14361', user_id b'704826', rating b'5'\n"
     ]
    }
   ],
   "source": [
    "for i in train.take(1):\n",
    "    print('book {}, user_id {}, rating {}'.format(i[0], i[1], i[2]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "5e65ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book b'2044', user_id b'609952', rating b'5'\n"
     ]
    }
   ],
   "source": [
    "for i in test.take(1):\n",
    "    print('book {}, user_id {}, rating {}'.format(i[0], i[1], i[2]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "49e876f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.batch(8000).cache()\n",
    "cached_test = test.batch(4000).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "bd3f94c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'42803' b'545379' b'1'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in cached_train.take(1):\n",
    "    print(i[0])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "23fe9413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'20988' b'46890' b'35762' ... b'24217' b'7349' b'37794'], shape=(8000,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in cached_train.take(1):\n",
    "    print(i[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "65bd120e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "93/93 [==============================] - 4s 41ms/step - root_mean_squared_error: 1.7389 - loss: 2.9891 - regularization_loss: 0.0000e+00 - total_loss: 2.9891\n",
      "Epoch 2/3\n",
      "93/93 [==============================] - 3s 32ms/step - root_mean_squared_error: 0.9315 - loss: 0.8633 - regularization_loss: 0.0000e+00 - total_loss: 0.8633\n",
      "Epoch 3/3\n",
      "93/93 [==============================] - 3s 32ms/step - root_mean_squared_error: 0.8692 - loss: 0.7534 - regularization_loss: 0.0000e+00 - total_loss: 0.7534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db22930580>"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "d0b9bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 5ms/step - root_mean_squared_error: 1.0055 - loss: 0.9942 - regularization_loss: 0.0000e+00 - total_loss: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.005478024482727,\n",
       " 'loss': 0.5586927533149719,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 0.5586927533149719}"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "4c7576fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = int(df2.User.sample(1))\n",
    "samples = df.sample(20)[['ISBN']].values\n",
    "samples = np.concatenate((np.array([[user]*20]), samples.reshape(1,-1)), axis=0).T.astype(np.str_)\n",
    "# samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "4e3cbc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book title: Gathering Storm: America's Militia Threat | Rating: 2.816\n",
      "Book title: A Very Young Dancer | Rating: 2.816\n",
      "Book title: Cat Fear Street 45 | Rating: 3.170\n",
      "Book title: The Man Who Stole the Mona Lisa | Rating: 2.816\n",
      "Book title: Girl in Hyacinth Blue | Rating: 2.816\n",
      "Book title: Isaac Asimov's Werewolves | Rating: 3.961\n",
      "Book title: Cliges | Rating: 2.816\n",
      "Book title: How To Control Your Anxiety Before It Controls You | Rating: 2.816\n",
      "Book title: The Bookshop | Rating: 2.816\n",
      "Book title: Bones of the Earth | Rating: 2.816\n",
      "Book title: Der Lavendelgarten | Rating: 2.816\n",
      "Book title: Starman Jones | Rating: 2.816\n",
      "Book title: Baby wann heiratest du mich Ein Roman aus dem Beziehungsdschungel | Rating: 2.816\n",
      "Book title: The Seventh Plague Sigma Force 12 | Rating: 2.816\n",
      "Book title: Back to the Stone Age Pellucidar 5 | Rating: 2.519\n",
      "Book title: Children of the Ruins | Rating: 2.816\n",
      "Book title: Delaney's Desert Sheikh The Westmorelands 1 | Rating: 2.816\n",
      "Book title: Crime School Kathleen Mallory 6 | Rating: 2.816\n",
      "Book title: Ship Fever: Stories | Rating: 2.816\n",
      "Book title: Cat Spells: Cat Magic Through the Ages | Rating: 2.496\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(samples[:, 1], # samples ISBNs\n",
    "               model(tf.convert_to_tensor(samples, dtype=tf.string)) # calling the model in eval mode on sample ISBNs \n",
    "              ): \n",
    "    print( \"Book title: {} | Rating: {:.3f}\".format(\n",
    "        le_isbn.inverse_transform(\n",
    "            np.array(new_book_title_stringlookup.call(tf.constant(i))).reshape(-1))[0], # retrieving book title using stringlook up\n",
    "        j[0])) # rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c311f5",
   "metadata": {},
   "source": [
    "Given the relative sparsity of data, most books will have similar scores, with a fewer number having unique scores. To tackle this problem one can create richer ranking models using richer features, such as the user's favourite genres and book genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d1b50dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46330</th>\n",
       "      <td>46330</td>\n",
       "      <td>['Fiction', 'Poetry', 'Short Stories', 'Sports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30068</th>\n",
       "      <td>30068</td>\n",
       "      <td>['Science Fiction', 'Fiction', 'Science Fictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49574</th>\n",
       "      <td>49574</td>\n",
       "      <td>['Nonfiction', 'Self Help', 'Psychology', 'Neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36904</th>\n",
       "      <td>36904</td>\n",
       "      <td>['Fiction', 'Novels']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20708</th>\n",
       "      <td>20708</td>\n",
       "      <td>['Fantasy', 'Science Fiction', 'Fiction', 'Sci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ISBN                                             Genres\n",
       "46330  46330  ['Fiction', 'Poetry', 'Short Stories', 'Sports...\n",
       "30068  30068  ['Science Fiction', 'Fiction', 'Science Fictio...\n",
       "49574  49574  ['Nonfiction', 'Self Help', 'Psychology', 'Neu...\n",
       "36904  36904                              ['Fiction', 'Novels']\n",
       "20708  20708  ['Fantasy', 'Science Fiction', 'Fiction', 'Sci..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first genre in the list indicates the dominant genre of the book\n",
    "# for example: ISBN 46246 is generally mystery, then fiction, then more specifically, a spy thriller\n",
    "df.groupby('ISBN', as_index=False).first()[['ISBN', 'Genres']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f5dff289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bf7cf3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "user_genres_mapping = defaultdict()\n",
    "for user in df2.User.unique():\n",
    "    records = []\n",
    "    for record in df[df2.User == user].Genres:\n",
    "        records += ast.literal_eval(record)\n",
    "    for val, col_name in zip(Counter(records).most_common(4), ['User_First_Cat', \n",
    "                                                               'User_Second_Cat',\n",
    "                                                               'User_Third_Cat',\n",
    "                                                               'User_Fourth_Cat']):\n",
    "        for element in df2[df2.User==user].index:\n",
    "            df2.at[element,col_name] = val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cf9870ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_First_Cat</th>\n",
       "      <th>User_Second_Cat</th>\n",
       "      <th>User_Third_Cat</th>\n",
       "      <th>User_Fourth_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1405400</th>\n",
       "      <td>Sequential Art</td>\n",
       "      <td>Comics</td>\n",
       "      <td>Graphic Novels</td>\n",
       "      <td>Graphic Novels Comics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370968</th>\n",
       "      <td>Historical</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038182</th>\n",
       "      <td>Literature</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226401</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Historical Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685159</th>\n",
       "      <td>Romance</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>Womens Fiction</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_First_Cat User_Second_Cat      User_Third_Cat  \\\n",
       "1405400  Sequential Art          Comics      Graphic Novels   \n",
       "1370968      Historical         Fantasy  Historical Fiction   \n",
       "1038182      Literature      Historical             Fiction   \n",
       "1226401         Mystery      Historical             Fiction   \n",
       "685159          Romance         Mystery      Womens Fiction   \n",
       "\n",
       "               User_Fourth_Cat  \n",
       "1405400  Graphic Novels Comics  \n",
       "1370968                Fiction  \n",
       "1038182               Classics  \n",
       "1226401     Historical Fiction  \n",
       "685159                 Fiction  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(5).iloc[:, 4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2f5db142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('TrainDataWithUserGenres.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b8dfb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in df2.ISBN.unique():\n",
    "    genres = ast.literal_eval([record for record in df2[df2.ISBN==book]['Genres'][:1]][0])\n",
    "    for genre, col_name in zip(genres[:4], ['Book_First_Cat', \n",
    "                               'Book_Second_Cat',\n",
    "                               'Book_Third_Cat',\n",
    "                               'Book_Fourth_Cat']):\n",
    "        if genre:\n",
    "            for element in df2[df2.ISBN==book].index:\n",
    "                df2.at[element,col_name] = genre\n",
    "\n",
    "df2.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2c2a7638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_First_Cat</th>\n",
       "      <th>Book_Second_Cat</th>\n",
       "      <th>Book_Third_Cat</th>\n",
       "      <th>Book_Fourth_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1481061</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Short Stories</td>\n",
       "      <td>Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195313</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26353</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>Classics</td>\n",
       "      <td>Cultural</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222866</th>\n",
       "      <td>Romance</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Historical Romance</td>\n",
       "      <td>Historical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248337</th>\n",
       "      <td>Childrens</td>\n",
       "      <td>Childrens</td>\n",
       "      <td>Picture Books</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Book_First_Cat Book_Second_Cat      Book_Third_Cat Book_Fourth_Cat\n",
       "1481061        Mystery         Fiction       Short Stories         Mystery\n",
       "1195313        Fantasy     Young Adult             Mystery         Fiction\n",
       "26353          Fiction        Classics            Cultural          France\n",
       "222866         Romance         Romance  Historical Romance      Historical\n",
       "248337       Childrens       Childrens       Picture Books         Animals"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(5).iloc[:, 8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e801fdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User', 'ISBN', 'RatingOf5', 'User_First_Cat', 'User_Second_Cat',\n",
       "       'User_Third_Cat', 'User_Fourth_Cat', 'Book_First_Cat',\n",
       "       'Book_Second_Cat', 'Book_Third_Cat', 'Book_Fourth_Cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.drop(columns='Genres', inplace=True)\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9fe3ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = df2.pop('RatingOf5')\n",
    "df2.insert(0, 'RatingOf5', user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2e5122a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RatingOf5', 'User', 'ISBN', 'User_First_Cat', 'User_Second_Cat',\n",
       "       'User_Third_Cat', 'User_Fourth_Cat', 'Book_First_Cat',\n",
       "       'Book_Second_Cat', 'Book_Third_Cat', 'Book_Fourth_Cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f98de319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Final_Ranker_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "d330c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Final_Ranker_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "44980614",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2 = tf.data.Dataset.from_tensor_slices(df2.astype('str').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "b5e607d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df2)*0.8)\n",
    "train2 = tf.data.Dataset.from_tensor_slices(\n",
    "    df2[df2.columns][:train_size].astype('str').values).shuffle(100000)\n",
    "\n",
    "test2 = tf.data.Dataset.from_tensor_slices(\n",
    "    df2[df2.columns][train_size:].astype('str').values).shuffle(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "bac14f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'153225' b'31111' b'Fiction' b'Gothic' b'Short Stories' b'Mystery'\n",
      " b'Gothic' b'Fiction' b'None' b'None'], shape=(10,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in train2.take(1):\n",
    "    print(i[1:]) # features, excluding label\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "18726010",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = []\n",
    "for i in df2.columns[3:]:\n",
    "    unique_genres += list(df2[f'{i}'].unique() )\n",
    "unique_genres = np.unique(unique_genres.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7fadc05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_lookup = tf.keras.layers.StringLookup(mask_token=None)\n",
    "genre_lookup.adapt(unique_genres)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "52239a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_lookup.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1d16e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df2.columns[3:]:\n",
    "    for i in df2.sample(1000)[column]: # samples 1000 rows from each columns to ensure the stringlookup isn't missing \n",
    "                                       # any categories\n",
    "        genre_lookup.call(tf.constant(i))\n",
    "#         print(i, genre_lookup.call(tf.constant(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dd20f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ranker_genre_lookup\", genre_lookup.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "9443444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id_stringlookup = tf.keras.layers.StringLookup(mask_token=None)\n",
    "new_user_id_stringlookup.set_weights(np.load(\"ranker_user_ids_vocabulary.npy\", allow_pickle=True))\n",
    "\n",
    "new_book_title_stringlookup = tf.keras.layers.StringLookup(mask_token=None)\n",
    "new_book_title_stringlookup.set_weights(np.load(\"ranker_book_titles_vocabulary.npy\", allow_pickle=True))\n",
    "\n",
    "genre_lookup = tf.keras.layers.StringLookup(mask_token=None)\n",
    "genre_lookup.set_weights(np.load(\"ranker_genre_lookup.npy\", allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "6e8e4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique User ID counts:  115058 115059\n",
      "Unique ISBN counts:  54466 54467\n",
      "Unique genre counts:  731 732\n"
     ]
    }
   ],
   "source": [
    "# compare vocab against original data as a sanity check; the incremental value contains the 'UNK' token\n",
    "print(\"Unique User ID counts: \", len(df2[\"User\"].unique()), new_user_id_stringlookup.vocabulary_size())\n",
    "print(\"Unique ISBN counts: \", len(df2[\"ISBN\"].unique()), new_book_title_stringlookup.vocabulary_size())\n",
    "print(\"Unique genre counts: \", len(unique_genres), genre_lookup.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "2788f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel_(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, book_title_stringlookup, user_id_stringlookup, genre_lookup):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "        genre_emb_dim = 4\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([user_id_stringlookup,\n",
    "          tf.keras.layers.Embedding(user_id_stringlookup.vocabulary_size()+1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for books.\n",
    "        self.book_embeddings = tf.keras.Sequential([book_title_stringlookup,\n",
    "          tf.keras.layers.Embedding(book_title_stringlookup.vocabulary_size()+1, embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "        self.user_genre_1_embeddings = tf.keras.Sequential([genre_lookup,\n",
    "          tf.keras.layers.Embedding(genre_lookup.vocabulary_size()+1, genre_emb_dim)\n",
    "        ])\n",
    "        self.user_genre_2_embeddings = tf.keras.Sequential([genre_lookup,\n",
    "          tf.keras.layers.Embedding(genre_lookup.vocabulary_size()+1, genre_emb_dim)\n",
    "        ])\n",
    "        self.user_genre_3_embeddings = tf.keras.Sequential([genre_lookup,\n",
    "          tf.keras.layers.Embedding(genre_lookup.vocabulary_size()+1, genre_emb_dim)\n",
    "        ])\n",
    "        self.user_genre_4_embeddings = tf.keras.Sequential([genre_lookup,\n",
    "          tf.keras.layers.Embedding(genre_lookup.vocabulary_size()+1, genre_emb_dim)\n",
    "        ])\n",
    "        self.book_genre_1_embeddings = tf.keras.Sequential([genre_lookup,\n",
    "          tf.keras.layers.Embedding(genre_lookup.vocabulary_size()+1, genre_emb_dim)\n",
    "        ])\n",
    "        self.book_genre_2_embeddings = tf.keras.Sequential([genre_lookup,\n",
    "          tf.keras.layers.Embedding(genre_lookup.vocabulary_size()+1, genre_emb_dim)\n",
    "        ])\n",
    "        self.book_genre_3_embeddings = tf.keras.Sequential([genre_lookup,\n",
    "          tf.keras.layers.Embedding(genre_lookup.vocabulary_size()+1, genre_emb_dim)\n",
    "        ])\n",
    "        self.book_genre_4_embeddings = tf.keras.Sequential([genre_lookup,\n",
    "          tf.keras.layers.Embedding(genre_lookup.vocabulary_size()+1, genre_emb_dim)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, book_title, user_genre_cat_1, user_genre_cat_2, user_genre_cat_3, user_genre_cat_4, \\\n",
    "        book_genre_cat_1, book_genre_cat_2, book_genre_cat_3, book_genre_cat_4 = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        book_embedding = self.book_embeddings(book_title)\n",
    "        user_genre_1_embeddings = self.user_genre_1_embeddings(user_genre_cat_1)\n",
    "        user_genre_2_embeddings = self.user_genre_2_embeddings(user_genre_cat_2)\n",
    "        user_genre_3_embeddings = self.user_genre_3_embeddings(user_genre_cat_3)\n",
    "        user_genre_4_embeddings = self.user_genre_4_embeddings(user_genre_cat_4)\n",
    "        book_genre_1_embeddings = self.book_genre_1_embeddings(book_genre_cat_1)\n",
    "        book_genre_2_embeddings = self.book_genre_2_embeddings(book_genre_cat_2)\n",
    "        book_genre_3_embeddings = self.book_genre_3_embeddings(book_genre_cat_3)\n",
    "        book_genre_4_embeddings = self.book_genre_4_embeddings(book_genre_cat_4)\n",
    "\n",
    "        return self.ratings(tf.concat([user_embedding, book_embedding, user_genre_1_embeddings, \n",
    "                                       user_genre_2_embeddings, user_genre_3_embeddings, user_genre_4_embeddings,\n",
    "                                      book_genre_1_embeddings, book_genre_2_embeddings, \n",
    "                                      book_genre_3_embeddings, book_genre_4_embeddings], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "f6a9a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRecommenderModel_(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel_(new_book_title_stringlookup, \n",
    "                                                          new_user_id_stringlookup, \n",
    "                                                          genre_lookup)\n",
    "        \n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "          loss = tf.keras.losses.MeanSquaredError(),\n",
    "          metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features) -> tf.Tensor:       \n",
    "        temp = tuple()\n",
    "        for i in range(0,10):        \n",
    "            temp += (features[:, i],)\n",
    "        return self.ranking_model(temp)\n",
    "\n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "\n",
    "        labels =  tf.strings.to_number(features[:,0])\n",
    "        rating_predictions = self(features[:, 1:])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "54b83e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BookRecommenderModel_()\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "d94a600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train2 = train2.batch(8000).cache()\n",
    "cached_test2 = test2.batch(4000).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "1eb56a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "93/93 [==============================] - 5s 46ms/step - root_mean_squared_error: 1.3356 - loss: 1.7692 - regularization_loss: 0.0000e+00 - total_loss: 1.7692\n",
      "Epoch 2/2\n",
      "93/93 [==============================] - 3s 33ms/step - root_mean_squared_error: 0.8832 - loss: 0.7761 - regularization_loss: 0.0000e+00 - total_loss: 0.7761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dae12074f0>"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(cached_train2, epochs=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "56707050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 3ms/step - root_mean_squared_error: 0.9680 - loss: 0.9238 - regularization_loss: 0.0000e+00 - total_loss: 0.9238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9679808616638184, 0.5815986394882202, 0, 0.5815986394882202]"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(cached_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "1e9dc692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RatingOf5', 'User', 'ISBN', 'User_First_Cat', 'User_Second_Cat',\n",
       "       'User_Third_Cat', 'User_Fourth_Cat', 'Book_First_Cat',\n",
       "       'Book_Second_Cat', 'Book_Third_Cat', 'Book_Fourth_Cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "bc9467c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 358987\n"
     ]
    }
   ],
   "source": [
    "# user = int(df2.User.sample(1))\n",
    "print(f\"User: {user}\")\n",
    "\n",
    "genres = df2[df2.User==user].iloc[0, 3:7].to_list()\n",
    "test_sample = {'RatingOf5': None,\n",
    "               'User': user,\n",
    "               'ISBN': None}\n",
    "\n",
    "for i, genre in enumerate(genres):\n",
    "    test_sample[df2.columns[i+3]] = genre\n",
    "for i in range(4):\n",
    "    test_sample[df2.columns[i+7]] = None\n",
    "    \n",
    "test_sample = pd.DataFrame(data=test_sample, index=range(20))\n",
    "\n",
    "book_samples = df2.sample(20)    \n",
    "for i in range(11):\n",
    "    curr_col = df2.columns[i]\n",
    "    if i == 2 or i > 6:\n",
    "        test_sample[curr_col] = book_samples[curr_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "87906c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Cafe on the Nile 3.8767078\n",
      "Chinhominey's Secret 3.6498048\n",
      "365 Meditations for Teachers 3.6498046\n",
      "A Little Zit On The Side 3.647118\n",
      "A Stranger in the Mirror 3.610251\n",
      "2024: A Graphic Novel 3.5916674\n",
      "Forensic Science: An Introduction to Criminalistics 3.581554\n",
      "A Tour of the Calculus 3.581554\n",
      "Hollywood Wives  The New Generation Hollywood Series 4 3.5593615\n",
      "The Happiest Baby on the Block: The New Way to Calm Crying and Help Your Newborn Baby Sleep Longer 3.5385542\n",
      "Love and Friendship 3.5350723\n",
      "A Bitter Peace 3.520727\n",
      "My Indecision Is Final: The Spectacular Rise and Fall of Goldcrest Films the Independent Studio That Challenged Hollywood 3.5139375\n",
      "The Absent City 3.5108807\n",
      "Doom of the Darksword The Darksword Trilogy 2 3.4930618\n",
      "Clockers 3.457056\n",
      "The End of Tragedy 3.4450378\n",
      "The Enchanted Wood The Faraway Tree 1 3.4417443\n",
      "Sextopia 3.40513\n",
      "Noninterference 3.3981323\n"
     ]
    }
   ],
   "source": [
    "rankings = list()\n",
    "for i,j in zip(test_sample.values[:, 2], # samples ISBNs\n",
    "               model2(tf.convert_to_tensor(test_sample.values.astype(np.str_), dtype=tf.string)) # calling the model in eval mode on sample ISBNs \n",
    "              ):\n",
    "    book_title = le_isbn.inverse_transform(\n",
    "            np.array(new_book_title_stringlookup.call(tf.constant(str(i)))).reshape(-1))[0]\n",
    "    rankings.append((j[0].numpy(), # book title\n",
    "                    book_title) # predicted book ranking\n",
    "                   )\n",
    "\n",
    "for i in sorted(rankings)[::-1]:\n",
    "    print(i[1], i[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "b85bede4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RatingOf5</th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>User_First_Cat</th>\n",
       "      <th>User_Second_Cat</th>\n",
       "      <th>User_Third_Cat</th>\n",
       "      <th>User_Fourth_Cat</th>\n",
       "      <th>Book_First_Cat</th>\n",
       "      <th>Book_Second_Cat</th>\n",
       "      <th>Book_Third_Cat</th>\n",
       "      <th>Book_Fourth_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>358987</td>\n",
       "      <td>43405</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Christian</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>Classics</td>\n",
       "      <td>Childrens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>358987</td>\n",
       "      <td>14061</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Christian</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Horror</td>\n",
       "      <td>Classics</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RatingOf5    User   ISBN User_First_Cat User_Second_Cat User_Third_Cat  \\\n",
       "0      None  358987  43405     Historical         Fiction      Christian   \n",
       "1      None  358987  14061     Historical         Fiction      Christian   \n",
       "\n",
       "  User_Fourth_Cat Book_First_Cat     Book_Second_Cat Book_Third_Cat  \\\n",
       "0      Nonfiction     Historical  Historical Fiction       Classics   \n",
       "1      Nonfiction         Horror            Classics        Mystery   \n",
       "\n",
       "  Book_Fourth_Cat  \n",
       "0       Childrens  \n",
       "1         Fiction  "
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "3cd8971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.RatingOf5 = '0' # reassining RatingOf5 to 0 since the initial model takes in string literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "59a9f99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [User, ISBN, RatingOf5, User_First_Cat, User_Second_Cat, User_Third_Cat, User_Fourth_Cat, Book_First_Cat, Book_Second_Cat, Book_Third_Cat, Book_Fourth_Cat]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "ratings = test_sample.pop('RatingOf5')\n",
    "books = test_sample.pop('ISBN')\n",
    "test_sample.insert(1, 'ISBN', books)\n",
    "test_sample.insert(2, 'RatingOf5', ratings)\n",
    "print(test_sample.head(0))\n",
    "test_sample = test_sample.values.astype(np.str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "65097489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book title: A Little Zit On The Side | Rating: 2.816\n",
      "Book title: The Happiest Baby on the Block: The New Way to Calm Crying and Help Your Newborn Baby Sleep Longer | Rating: 2.909\n",
      "Book title: Doom of the Darksword The Darksword Trilogy 2 | Rating: 2.816\n",
      "Book title: A Stranger in the Mirror | Rating: 2.816\n",
      "Book title: The End of Tragedy | Rating: 3.638\n",
      "Book title: Chinhominey's Secret | Rating: 2.816\n",
      "Book title: 2024: A Graphic Novel | Rating: 2.816\n",
      "Book title: A Cafe on the Nile | Rating: 2.816\n",
      "Book title: Clockers | Rating: 2.816\n",
      "Book title: My Indecision Is Final: The Spectacular Rise and Fall of Goldcrest Films the Independent Studio That Challenged Hollywood | Rating: 2.816\n",
      "Book title: Noninterference | Rating: 2.816\n",
      "Book title: The Enchanted Wood The Faraway Tree 1 | Rating: 2.816\n",
      "Book title: A Bitter Peace | Rating: 2.816\n",
      "Book title: Love and Friendship | Rating: 2.715\n",
      "Book title: The Absent City | Rating: 2.816\n",
      "Book title: Hollywood Wives  The New Generation Hollywood Series 4 | Rating: 3.129\n",
      "Book title: Sextopia | Rating: 2.816\n",
      "Book title: Forensic Science: An Introduction to Criminalistics | Rating: 2.816\n",
      "Book title: 365 Meditations for Teachers | Rating: 2.816\n",
      "Book title: A Tour of the Calculus | Rating: 3.445\n"
     ]
    }
   ],
   "source": [
    "# Comparing the original model with the same sample and user\n",
    "\n",
    "for i,j in zip(test_sample[:, 1], # samples ISBNs\n",
    "               model(tf.convert_to_tensor(test_sample[:, :3], dtype=tf.string)) # calling the model in eval mode on sample ISBNs \n",
    "              ): \n",
    "    print( \"Book title: {} | Rating: {:.3f}\".format(\n",
    "        le_isbn.inverse_transform(\n",
    "            np.array(new_book_title_stringlookup.call(tf.constant(i))).reshape(-1))[0], # retrieving book title using stringlook up\n",
    "        j[0])) # rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519a9d1",
   "metadata": {},
   "source": [
    "Egineering extra features did provide a richer representation of users and books and thus rankings for the target user with exactly the number of distinct ranks as te number of book samples. The original model still fails to provide a unique rank for the majority of observations except 4-5 unique scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045270fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
