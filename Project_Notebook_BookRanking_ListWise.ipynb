{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ae282d",
   "metadata": {
    "id": "67ae282d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_ranking as tfr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c2d22",
   "metadata": {
    "id": "0d5c2d22"
   },
   "source": [
    "Importing and organizing the raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0260233",
   "metadata": {
    "id": "c0260233"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# data = list()\n",
    "# for file in os.listdir(\"./data\"):\n",
    "##     if file != \"results_20000-24861.json\":\n",
    "#     with open(\"./data/\"+file, 'rb') as f:\n",
    "#         print(f\"Read {file}\")\n",
    "#         data_ = json.load(f)\n",
    "#         data += data_\n",
    "##     else:\n",
    "##         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7f572",
   "metadata": {
    "id": "0ee7f572"
   },
   "outputs": [],
   "source": [
    "# records = [{\"User\": record.get('user_id'), \n",
    "#            \"ISBN\": record.get('book_title'),\n",
    "#            \"RatingOf5\": record.get('stars'),\n",
    "#            \"Genres\": record.get('genres')\n",
    "#           } for record in data]\n",
    "# df = pd.DataFrame(records)\n",
    "# df.to_csv(\"USER_ISBN_RATING_GENRES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e423556",
   "metadata": {
    "id": "9e423556"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../USER_ISBN_RATING_GENRES.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce96ed",
   "metadata": {
    "id": "2bce96ed",
    "outputId": "566da9b7-2a27-4814-f577-de8b4b0022d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numer of unique books:  57198\n",
      "Total numer of unique users:  706880\n",
      "Total numer of reviews:  1733561\n",
      "Total numer of positive reviews:  936796\n",
      "Total numer of non-positive reviews:  201628\n",
      "Total numer of moderate reviews:  372374\n",
      "Total numer of  non-reviews:  222763\n"
     ]
    }
   ],
   "source": [
    "print(\"Total numer of unique books: \", len(df[\"ISBN\"].unique()))\n",
    "print(\"Total numer of unique users: \", len(df[\"User\"].unique()))\n",
    "print(\"Total numer of reviews: \", len(df))\n",
    "print(\"Total numer of positive reviews: \", len(df[df[\"RatingOf5\"] > 3]))\n",
    "print(\"Total numer of non-positive reviews: \", len(df[df[\"RatingOf5\"] < 3]))\n",
    "print(\"Total numer of moderate reviews: \", len(df[df[\"RatingOf5\"] == 3]))\n",
    "print(\"Total numer of  non-reviews: \", sum(df[\"RatingOf5\"].isna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45c216",
   "metadata": {
    "id": "fb45c216"
   },
   "source": [
    "Although I'll use a TF stringlookup object to encode users, to keep users anonymous for the data exploration stage, I'll label encode them as IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129056e7",
   "metadata": {
    "id": "129056e7",
    "outputId": "46abcce7-4d64-47ba-f98f-e2b0ed71ae11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1733561, 706880)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df[\"User\"])\n",
    "transformed = le.transform(df[\"User\"])\n",
    "len(transformed), len(np.unique(transformed, return_counts=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5427f",
   "metadata": {
    "id": "efc5427f",
    "outputId": "7a1e152a-9cf5-4ada-b828-75a990cd50d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ranker_fitted_label_encoder.pkl']"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(le, \"ranker_fitted_label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9afe7b",
   "metadata": {
    "id": "9c9afe7b"
   },
   "outputs": [],
   "source": [
    "le = joblib.load(\"ranker_fitted_label_encoder.pkl\")\n",
    "transformed = le.transform(df[\"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649eba3",
   "metadata": {
    "id": "6649eba3",
    "outputId": "e026bea1-638a-4e08-9f7c-b889a07a2edf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    423114\n",
       "1    241063\n",
       "2    659623\n",
       "3    557019\n",
       "4     44930\n",
       "Name: User, dtype: int32"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"User\"] = transformed\n",
    "df[\"User\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a364b",
   "metadata": {
    "id": "848a364b"
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1817c",
   "metadata": {
    "id": "8cf1817c"
   },
   "source": [
    "**I'm going to reserve a random sample of 10 observations to test recommendations as observations that the model has not seen before when developing the production package.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1be76c",
   "metadata": {
    "id": "1b1be76c"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea0c85",
   "metadata": {
    "id": "b5ea0c85"
   },
   "outputs": [],
   "source": [
    "sample = df.groupby(\"ISBN\").count()[df.groupby(\"ISBN\").count()[\"User\"] > 5][\"User\"]. \\\n",
    "    sort_values(ascending=False).sample(20).index\n",
    "loop = True\n",
    "while True:\n",
    "    new_sample=df[df[\"ISBN\"].isin(sample)].sample(10)['ISBN']\n",
    "    if len(new_sample.unique()) == 10:\n",
    "        sample_to_keep = new_sample\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f41a51",
   "metadata": {
    "id": "03f41a51"
   },
   "outputs": [],
   "source": [
    "sample = df[df.index.isin(sample_to_keep.index)][['User', 'ISBN', 'RatingOf5']]\n",
    "index_to_drop = sample.index\n",
    "sample.to_csv('ranker_test.csv', index=False)\n",
    "df.drop(index=index_to_drop, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9dd36",
   "metadata": {
    "id": "24e9dd36",
    "outputId": "84c73662-a98c-4311-dee2-b1ac9de29e92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>RatingOf5</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [User, ISBN, RatingOf5, Genres]\n",
       "Index: []"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index.isin(index_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb651465",
   "metadata": {
    "id": "bb651465",
    "outputId": "3589922e-adb5-43c9-866b-2954c1eb71a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320727</td>\n",
       "      <td>What Went Wrong at Enron: Everyone's Guide to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625088</td>\n",
       "      <td>Guerrilla Learning: How to Give Your Kids a Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>618800</td>\n",
       "      <td>Eastern Sun Winter Moon: An Autobiographical O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>411288</td>\n",
       "      <td>Raspberry Crush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198921</td>\n",
       "      <td>Pooh: Just Be Nice AND NOT TOO ROUGH SPECIAL E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>258203</td>\n",
       "      <td>The Life and Adventures of Nicholas Nickleby V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>336651</td>\n",
       "      <td>Silver Flame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>684707</td>\n",
       "      <td>Nothing That Meets the Eye: The Uncollected St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>597291</td>\n",
       "      <td>Das Tor ins Nichts Der Magier 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>404510</td>\n",
       "      <td>Berserk: Motiveless Random Massacres</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User                                               ISBN\n",
       "0  320727  What Went Wrong at Enron: Everyone's Guide to ...\n",
       "1  625088  Guerrilla Learning: How to Give Your Kids a Re...\n",
       "2  618800  Eastern Sun Winter Moon: An Autobiographical O...\n",
       "3  411288                                    Raspberry Crush\n",
       "4  198921  Pooh: Just Be Nice AND NOT TOO ROUGH SPECIAL E...\n",
       "5  258203  The Life and Adventures of Nicholas Nickleby V...\n",
       "6  336651                                       Silver Flame\n",
       "7  684707  Nothing That Meets the Eye: The Uncollected St...\n",
       "8  597291                    Das Tor ins Nichts Der Magier 2\n",
       "9  404510               Berserk: Motiveless Random Massacres"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('ranker_test.csv')[['User', 'ISBN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a738f9",
   "metadata": {
    "id": "d1a738f9"
   },
   "outputs": [],
   "source": [
    "df[[\"User\", \"ISBN\", \"RatingOf5\", \"Genres\"]].to_csv('ranker_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a990170",
   "metadata": {
    "id": "0a990170",
    "outputId": "fa5d9a31-cacf-41db-c376-98a84a1c0829"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423114</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241063</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>659623</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>557019</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44930</td>\n",
       "      <td>Kiss Hollywood Goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User                    ISBN\n",
       "0  423114  Kiss Hollywood Goodbye\n",
       "1  241063  Kiss Hollywood Goodbye\n",
       "2  659623  Kiss Hollywood Goodbye\n",
       "3  557019  Kiss Hollywood Goodbye\n",
       "4   44930  Kiss Hollywood Goodbye"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('ranker_train_data.csv', nrows=5)[[\"User\", \"ISBN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1090b10",
   "metadata": {
    "id": "c1090b10"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ranker_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000ec0f",
   "metadata": {
    "id": "c000ec0f",
    "outputId": "50790a60-0999-4321-f0a2-2ba67395a05c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User         0\n",
       "ISBN         0\n",
       "RatingOf5    0\n",
       "Genres       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc6642",
   "metadata": {
    "id": "e1dc6642"
   },
   "source": [
    "#### Reducing dimentionality\n",
    "\n",
    "With ~ 700k users and 60k books, the embeddings for the two embedding \"towers\" that the recommender model is going to be based on will generately an extremely large model. Practically, I would like to demonstrate the end-to-end data science pipeline by being able to package my model and make it available publicly for my API to access as well as for those interested which is why reduce the recommendations to those users who given more than 2 review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78f7ce",
   "metadata": {
    "id": "af78f7ce",
    "outputId": "43daa8f7-38f9-4efb-ca5c-b6b0ae0ebc3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User\n",
       "0         41\n",
       "7          3\n",
       "8          4\n",
       "25         3\n",
       "31         3\n",
       "          ..\n",
       "706863    12\n",
       "706867     6\n",
       "706870     6\n",
       "706871     4\n",
       "706879     4\n",
       "Name: ISBN, Length: 115058, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data = df.groupby(\"User\").count()\n",
    "grouped_data[grouped_data[\"ISBN\"] > 2]['ISBN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffddbc",
   "metadata": {
    "id": "dbffddbc",
    "outputId": "0dfe9c27-3bcb-443a-d706-a36a9bd6440b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_keep = grouped_data[grouped_data[\"ISBN\"] > 2].index\n",
    "set(idx_to_keep) == set(df[df[\"User\"].isin(idx_to_keep)][\"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217c46f",
   "metadata": {
    "id": "e217c46f",
    "outputId": "b0853a66-d63e-4f84-a44b-b15e9e238f82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1265091</th>\n",
       "      <td>461604</td>\n",
       "      <td>The Language of Letting Go: Daily Meditations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904811</th>\n",
       "      <td>171370</td>\n",
       "      <td>Confessional Liam Devlin 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33619</th>\n",
       "      <td>307367</td>\n",
       "      <td>What Happened to Patrick's Dinosaurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166922</th>\n",
       "      <td>444018</td>\n",
       "      <td>I Sing the Body Electronic: A Year with Micros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759433</th>\n",
       "      <td>442750</td>\n",
       "      <td>Let's Fly a Kite Charlie Brown A Book About th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           User                                               ISBN\n",
       "1265091  461604  The Language of Letting Go: Daily Meditations ...\n",
       "904811   171370                         Confessional Liam Devlin 3\n",
       "33619    307367               What Happened to Patrick's Dinosaurs\n",
       "166922   444018  I Sing the Body Electronic: A Year with Micros...\n",
       "759433   442750  Let's Fly a Kite Charlie Brown A Book About th..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.User.isin(idx_to_keep)]\n",
    "df.sample(5)[['User', 'ISBN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb70607",
   "metadata": {
    "id": "2fb70607"
   },
   "source": [
    "At this point we have an index of user that have more than 2 reviews (of different books). Our new DataFrame object will only comprise those users and their respectively reviewed books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90e802",
   "metadata": {
    "id": "3a90e802",
    "outputId": "a64fcf43-62ec-4992-d6da-b165f040f5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique users remaining:  115058\n",
      "# of unique books remaining:  54466\n"
     ]
    }
   ],
   "source": [
    "# also ensure that the grouping and querying was sane\n",
    "print(\"# of unique users remaining: \", len(df.groupby('User').count()))\n",
    "\n",
    "# also check out how many unique books were lost in the process of trimming \n",
    "# down the dataset (only about 500)\n",
    "\n",
    "print(\"# of unique books remaining: \", len(df.groupby('ISBN').count()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e941df",
   "metadata": {
    "id": "99e941df"
   },
   "outputs": [],
   "source": [
    "# we can label encode the book ID's if required, otherwise, a TF stringlookup object can handle \n",
    "# a variety of string encodings well - as will follow\n",
    "\n",
    "le_isbn = LabelEncoder()\n",
    "df[\"ISBN\"] = le_isbn.fit_transform(df[\"ISBN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca302f44",
   "metadata": {
    "id": "ca302f44",
    "outputId": "351477f7-c31f-4296-aaa0-627cea60f6fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 924370 entries, 0 to 1510787\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   User       924370 non-null  int64 \n",
      " 1   ISBN       924370 non-null  int64 \n",
      " 2   RatingOf5  924370 non-null  int64 \n",
      " 3   Genres     924370 non-null  object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.User = df.User.astype(np.int64)\n",
    "df.ISBN = df.ISBN.astype(np.int64)\n",
    "df.RatingOf5 = df.RatingOf5.astype(np.int64)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348882f3",
   "metadata": {
    "id": "348882f3"
   },
   "source": [
    "Setting up tensors to batch for purposes of training the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3689c50",
   "metadata": {
    "id": "a3689c50"
   },
   "outputs": [],
   "source": [
    "books = tf.data.Dataset.from_tensor_slices(df['ISBN'].astype('str').values)\n",
    "ratings = tf.data.Dataset.from_tensor_slices(df[['User', 'ISBN', 'RatingOf5']].astype('str').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a97db",
   "metadata": {
    "id": "e95a97db"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(df)*0.8)\n",
    "train = tf.data.Dataset.from_tensor_slices(\n",
    "    df[[\"ISBN\", \"User\", \"RatingOf5\"]][:train_size].astype('str').values).shuffle(100000)\n",
    "test = tf.data.Dataset.from_tensor_slices(\n",
    "    df[[\"ISBN\", \"User\", \"RatingOf5\"]][train_size:].astype('str').values).shuffle(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07607de2",
   "metadata": {
    "id": "07607de2",
    "outputId": "cf571363-1169-483e-aa8e-0dc1c8bead6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'18368' b'85574' b'5'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in test.take(1):\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae1f6b",
   "metadata": {
    "id": "49ae1f6b"
   },
   "source": [
    "String look up creates a vocabulary dictionary of string-value pairs since I'll be embedding my ISBN's and users ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c80e2",
   "metadata": {
    "id": "c94c80e2"
   },
   "outputs": [],
   "source": [
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(ratings.map(lambda x: x[0]))\n",
    "\n",
    "book_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "book_titles_vocabulary.adapt(ratings.map(lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411626e7",
   "metadata": {
    "id": "411626e7"
   },
   "outputs": [],
   "source": [
    "np.save(\"ranker_user_ids_vocabulary\", user_ids_vocabulary.get_weights())\n",
    "np.save(\"ranker_book_titles_vocabulary\", book_titles_vocabulary.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f74510",
   "metadata": {
    "id": "d0f74510"
   },
   "outputs": [],
   "source": [
    "new_user_id_stringlookup = tf.keras.layers.StringLookup(mask_token=None)\n",
    "new_user_id_stringlookup.set_weights(np.load(\"ranker_user_ids_vocabulary.npy\", allow_pickle=True))\n",
    "\n",
    "new_book_title_stringlookup = tf.keras.layers.StringLookup(mask_token=None)\n",
    "new_book_title_stringlookup.set_weights(np.load(\"ranker_book_titles_vocabulary.npy\", allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee2370a",
   "metadata": {
    "id": "3ee2370a"
   },
   "outputs": [],
   "source": [
    "# user and book embedding model objects created outside the main ranking model\n",
    "\n",
    "embedding_dimension = 32\n",
    "user_model = tf.keras.Sequential([\n",
    "    new_user_id_stringlookup,\n",
    "    tf.keras.layers.Embedding(new_user_id_stringlookup.vocabulary_size()+1 , embedding_dimension)\n",
    "])\n",
    "\n",
    "book_model = tf.keras.Sequential([\n",
    "    new_book_title_stringlookup,\n",
    "    tf.keras.layers.Embedding(new_book_title_stringlookup.vocabulary_size()+1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b148581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to support transforming tabular data into tensor data in listwise format \n",
    "# adapted from https://github.com/tensorflow/recommenders/blob/main/tensorflow_recommenders/examples/movielens.py\n",
    "from listwise_utility import (sample_listwise, \n",
    "                              RankingModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76435d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"./sample1\"\n",
    "path2 = \"./sample2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fdb4e",
   "metadata": {
    "id": "482fdb4e"
   },
   "outputs": [],
   "source": [
    "train_ds = sample_listwise(\n",
    "    train,\n",
    "    num_list_per_user=50,\n",
    "    num_examples_per_list=5,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4013511",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(\n",
    "    train_ds, path, compression='GZIP'\n",
    ")\n",
    "with open(path1 + '/element_spec1', 'wb') as out_:  # also save the element_spec to disk for future loading\n",
    "    pickle.dump(sample1.element_spec, out_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03671e",
   "metadata": {
    "id": "6a03671e"
   },
   "outputs": [],
   "source": [
    "test_ds = sample_listwise(\n",
    "    test,\n",
    "    num_list_per_user=50,\n",
    "    num_examples_per_list=5,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "421c4b99",
   "metadata": {
    "id": "421c4b99"
   },
   "outputs": [],
   "source": [
    "tf.data.experimental.save(\n",
    "    test_ds, path, compression='GZIP'\n",
    ")\n",
    "with open(path2 + '/element_spec2', 'wb') as out_:  # also save the element_spec to disk for future loading\n",
    "    pickle.dump(sample2.element_spec, out_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ffe136",
   "metadata": {},
   "source": [
    "I upload these datasets to Google Colab since my OS doesn't support tensorflow_ranking which features loss functions import to trainig listwise rankers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c79e8d",
   "metadata": {},
   "source": [
    "Some setup for training on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "m-Yv4oG48sV4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-Yv4oG48sV4",
    "outputId": "ee4bb4fe-5d4f-415c-8890-b44e383f9173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "QTrPLcMY9IE2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTrPLcMY9IE2",
    "outputId": "2b64ebf1-5ff3-4bed-f6e9-626d409e87e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046517602870779941   dataset_spec.pb  element_spec1\n",
      "14239500212799276046  element_spec     snapshot.metadata\n",
      "10931280481293917633  dataset_spec.pb  element_spec2  snapshot.metadata\n"
     ]
    }
   ],
   "source": [
    "!ls gdrive/MyDrive/sample1/\n",
    "!ls gdrive/MyDrive/sample2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c124aa8a",
   "metadata": {
    "id": "c124aa8a"
   },
   "outputs": [],
   "source": [
    "path = \"./gdrive/MyDrive/sample1\" # train\n",
    "path = \"./gdrive/MyDrive/sample2\" # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91076613",
   "metadata": {
    "id": "91076613"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(path + '/element_spec1', 'rb') as in_:\n",
    "    es = pickle.load(in_)\n",
    "\n",
    "train_ds = tf.data.experimental.load(\n",
    "    path, es, compression='GZIP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d79ca84",
   "metadata": {
    "id": "4d79ca84"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "cached_train = train_ds.batch(8192).cache()\n",
    "cached_test = test_ds.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "N-IkZO_PFnHu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-IkZO_PFnHu",
    "outputId": "baa6ee91-b879-4256-e36c-7a15736cfe0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': <tf.Tensor: shape=(4096,), dtype=string, numpy=\n",
      "array([b'31553', b'31553', b'31553', ..., b'7027', b'7027', b'7027'],\n",
      "      dtype=object)>, 'book_title': <tf.Tensor: shape=(4096, 5), dtype=string, numpy=\n",
      "array([[b'452505', b'303111', b'419904', b'47586', b'605443'],\n",
      "       [b'382244', b'357230', b'419904', b'594747', b'452505'],\n",
      "       [b'176086', b'357230', b'602363', b'382244', b'47586'],\n",
      "       ...,\n",
      "       [b'229307', b'262045', b'359386', b'406877', b'240836'],\n",
      "       [b'359386', b'582693', b'85789', b'229307', b'596214'],\n",
      "       [b'366356', b'229307', b'359386', b'265191', b'76474']],\n",
      "      dtype=object)>, 'user_rating': <tf.Tensor: shape=(4096, 5), dtype=string, numpy=\n",
      "array([[b'5', b'3', b'4', b'5', b'4'],\n",
      "       [b'5', b'4', b'4', b'3', b'5'],\n",
      "       [b'4', b'4', b'3', b'5', b'5'],\n",
      "       ...,\n",
      "       [b'4', b'4', b'5', b'5', b'5'],\n",
      "       [b'5', b'5', b'4', b'4', b'4'],\n",
      "       [b'3', b'4', b'5', b'4', b'4']], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "for i in cached_test.take(1):\n",
    "  print(i)\n",
    "#   j = {'user_id': i['user_id'][0],'book_title': i['book_title'][0], 'user_rating': i['user_rating'][0]}\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87089f",
   "metadata": {
    "id": "df87089f"
   },
   "source": [
    "##### MSE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b5689dc",
   "metadata": {
    "id": "4b5689dc"
   },
   "outputs": [],
   "source": [
    "# Ranking model that optimizes based on either MSE or an NDCGMetric from tensorflow_ranking\n",
    "mse_model = RankingModel(tf.keras.losses.MeanSquaredError(), user_model, book_model)\n",
    "mse_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96baf6d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96baf6d0",
    "outputId": "f987e115-de91-4cd4-8cd9-600136b9d020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f41800878c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f41800878c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "240/240 [==============================] - 46s 164ms/step - ndcg_metric: 0.8508 - root_mean_squared_error: 1.1673 - loss: 1.3614 - regularization_loss: 0.0000e+00 - total_loss: 1.3614\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 13s 54ms/step - ndcg_metric: 0.8512 - root_mean_squared_error: 1.0779 - loss: 1.1617 - regularization_loss: 0.0000e+00 - total_loss: 1.1617\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 13s 53ms/step - ndcg_metric: 0.8520 - root_mean_squared_error: 1.0776 - loss: 1.1610 - regularization_loss: 0.0000e+00 - total_loss: 1.1610\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 13s 54ms/step - ndcg_metric: 0.8522 - root_mean_squared_error: 1.0774 - loss: 1.1605 - regularization_loss: 0.0000e+00 - total_loss: 1.1605\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 13s 54ms/step - ndcg_metric: 0.8526 - root_mean_squared_error: 1.0772 - loss: 1.1602 - regularization_loss: 0.0000e+00 - total_loss: 1.1602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f410e399990>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_model.fit(cached_train, epochs=epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ce89e",
   "metadata": {
    "id": "fe5ce89e"
   },
   "source": [
    "##### Hinge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdbd71b6",
   "metadata": {
    "id": "fdbd71b6"
   },
   "outputs": [],
   "source": [
    "hinge_model = RankingModel(tfr.keras.losses.PairwiseHingeLoss(), user_model, book_model)\n",
    "hinge_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03cd1a13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03cd1a13",
    "outputId": "3d806f16-04ff-4b29-ba7f-2aa2e87db503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "240/240 [==============================] - 15s 61ms/step - ndcg_metric: 0.8522 - root_mean_squared_error: 4.4069 - loss: 1.3909 - regularization_loss: 0.0000e+00 - total_loss: 1.3909\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 13s 54ms/step - ndcg_metric: 0.8538 - root_mean_squared_error: 4.2699 - loss: 1.3828 - regularization_loss: 0.0000e+00 - total_loss: 1.3828\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 13s 55ms/step - ndcg_metric: 0.8560 - root_mean_squared_error: 4.4172 - loss: 1.3713 - regularization_loss: 0.0000e+00 - total_loss: 1.3713\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 13s 55ms/step - ndcg_metric: 0.8574 - root_mean_squared_error: 4.4307 - loss: 1.3603 - regularization_loss: 0.0000e+00 - total_loss: 1.3603\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 13s 54ms/step - ndcg_metric: 0.8585 - root_mean_squared_error: 4.3486 - loss: 1.3516 - regularization_loss: 0.0000e+00 - total_loss: 1.3516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40f9a40f90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_model.fit(cached_train, epochs=epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529d256",
   "metadata": {
    "id": "3529d256"
   },
   "source": [
    "##### Listwise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "747baecb",
   "metadata": {
    "id": "747baecb"
   },
   "outputs": [],
   "source": [
    "listwise_model = RankingModel(tfr.keras.losses.ListMLELoss(), user_model, book_model)\n",
    "listwise_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbd9b13d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbd9b13d",
    "outputId": "0726fdf2-6de3-4931-a131-a2e34766c8b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f40f99f5c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f40f99f5c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "240/240 [==============================] - 20s 72ms/step - ndcg_metric: 0.8580 - root_mean_squared_error: 3.8548 - loss: 4.7804 - regularization_loss: 0.0000e+00 - total_loss: 4.7804\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 17s 73ms/step - ndcg_metric: 0.8587 - root_mean_squared_error: 3.9389 - loss: 4.7670 - regularization_loss: 0.0000e+00 - total_loss: 4.7670\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 18s 73ms/step - ndcg_metric: 0.8589 - root_mean_squared_error: 4.0986 - loss: 4.7600 - regularization_loss: 0.0000e+00 - total_loss: 4.7600\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 17s 72ms/step - ndcg_metric: 0.8591 - root_mean_squared_error: 4.2325 - loss: 4.7560 - regularization_loss: 0.0000e+00 - total_loss: 4.7560\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 17s 71ms/step - ndcg_metric: 0.8591 - root_mean_squared_error: 4.2615 - loss: 4.7533 - regularization_loss: 0.0000e+00 - total_loss: 4.7533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40f9a68690>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listwise_model.fit(cached_train, epochs=epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NezZZcmWCdN7",
   "metadata": {
    "id": "NezZZcmWCdN7"
   },
   "source": [
    "##### Evaluating models using various loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "BTNnzsRGCPUT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTNnzsRGCPUT",
    "outputId": "42e1b81b-9bc7-4c96-c244-ef64e8bb33c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f40f99f5d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f40f99f5d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "118/118 [==============================] - 42s 108ms/step - ndcg_metric: 0.8556 - root_mean_squared_error: 1.1026 - loss: 1.2163 - regularization_loss: 0.0000e+00 - total_loss: 1.2163\n"
     ]
    }
   ],
   "source": [
    "mse_model_result = mse_model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ZRu-2JMUCPXU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRu-2JMUCPXU",
    "outputId": "d4879cd2-64fd-4942-dc82-0fb8efa6d191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f40f962c200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f40f962c200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "118/118 [==============================] - 5s 33ms/step - ndcg_metric: 0.8563 - root_mean_squared_error: 4.3173 - loss: 1.3669 - regularization_loss: 0.0000e+00 - total_loss: 1.3669\n"
     ]
    }
   ],
   "source": [
    "hinge_model_result = hinge_model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1gjmU6DlCZKq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gjmU6DlCZKq",
    "outputId": "0a14c7a4-24e1-4e63-9e5e-4b84e847f115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f40f957d290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f40f957d290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "118/118 [==============================] - 5s 38ms/step - ndcg_metric: 0.8563 - root_mean_squared_error: 4.1516 - loss: 4.7727 - regularization_loss: 0.0000e+00 - total_loss: 4.7727\n"
     ]
    }
   ],
   "source": [
    "listwise_model_result = listwise_model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bW-KRZzEEeAF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bW-KRZzEEeAF",
    "outputId": "1f56c996-384e-43c9-d8eb-81ee494854d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG of the MSE Model: 0.8556\n",
      "NDCG of the pairwise hinge loss model: 0.8563\n",
      "NDCG of the ListMLE model: 0.8563\n"
     ]
    }
   ],
   "source": [
    "print(\"NDCG of the MSE Model: {:.4f}\".format(mse_model_result[\"ndcg_metric\"]))\n",
    "print(\"NDCG of the pairwise hinge loss model: {:.4f}\".format(hinge_model_result[\"ndcg_metric\"]))\n",
    "print(\"NDCG of the ListMLE model: {:.4f}\".format(listwise_model_result[\"ndcg_metric\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiP0cwLTEm49",
   "metadata": {
    "id": "fiP0cwLTEm49"
   },
   "outputs": [],
   "source": [
    "mse_model.save('./gdrive/MyDrive/mse_model')\n",
    "hinge_model.save('./gdrive/MyDrive/hingle_model')\n",
    "listwise_model.save('./gdrive/MyDrive/listwise_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suG9CTo-IhKQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suG9CTo-IhKQ",
    "outputId": "fa74ac4c-ee89-4a9a-818b-350b8b8a38bc"
   },
   "outputs": [],
   "source": [
    "# inference based on the sample from the test set\n",
    "# taken earlier based no a single observation from the batch (1 user, 5 movies)\n",
    "\n",
    "for j in range(5):\n",
    "  print(listwise_model(i)[0,j,:]) \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project_Notebook_BookRecommender_Ranking_ListWise.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
